{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcVbC7voJVLO","outputId":"d88108b3-309d-47e1-8581-563a59fb1c7e","execution":{"iopub.status.busy":"2023-03-22T14:27:10.730288Z","iopub.execute_input":"2023-03-22T14:27:10.731344Z","iopub.status.idle":"2023-03-22T14:27:22.773301Z","shell.execute_reply.started":"2023-03-22T14:27:10.731306Z","shell.execute_reply":"2023-03-22T14:27:22.771790Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.26.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"#imports\nimport tensorflow as tf \ntf.__version__\nimport transformers\nimport os\nimport shutil\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nfrom transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification,TFBertForSequenceClassification\nfrom transformers import AutoTokenizer\nfrom transformers import BertTokenizerFast\nfrom transformers import BertTokenizer\n","metadata":{"id":"Tyy4f6XpvwS0","execution":{"iopub.status.busy":"2023-03-22T14:27:22.776079Z","iopub.execute_input":"2023-03-22T14:27:22.776527Z","iopub.status.idle":"2023-03-22T14:27:34.635345Z","shell.execute_reply.started":"2023-03-22T14:27:22.776457Z","shell.execute_reply":"2023-03-22T14:27:34.634228Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"u1mBqk6eWNEX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing and checking the data\ndef import_and_check_data():\n    df = pd.read_csv('/kaggle/input/14-data/1.4.csv', header = None) #1.4 is waseem's dataset\n    df.dropna(inplace = True)\n    df = df.rename(columns = {0:'tweet', 1:'label'})\n    df = df.sample(frac = 1) #shuffle\n    df.reset_index(inplace = True)\n    df.drop('index',inplace = True, axis=1)\n    df\n    print(df['label'].value_counts())\n    return df\n","metadata":{"id":"nuOeSU-jv4hU","colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"0cd2207b-41c4-43da-b999-fa0e57242a86","execution":{"iopub.status.busy":"2023-03-22T14:27:34.636891Z","iopub.execute_input":"2023-03-22T14:27:34.637751Z","iopub.status.idle":"2023-03-22T14:27:34.648061Z","shell.execute_reply.started":"2023-03-22T14:27:34.637704Z","shell.execute_reply":"2023-03-22T14:27:34.644049Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train_test_split(text,label):\n    from sklearn.model_selection import train_test_split\n    x_train, x_test, y_train, y_test = train_test_split(text,label, test_size = 0.2, random_state = 32)  \n    print('len of x_train ', len(x_train))\n    print('len of x_test ', len(x_test))\n    return x_train,x_test,y_train,y_test\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T16:24:30.994013Z","iopub.execute_input":"2023-03-22T16:24:30.994658Z","iopub.status.idle":"2023-03-22T16:24:31.001110Z","shell.execute_reply.started":"2023-03-22T16:24:30.994615Z","shell.execute_reply":"2023-03-22T16:24:30.999735Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_and_test_ds(x_train,x_test,y_train,y_test):\n    \n    tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n    \n    x_train, y_train = list(x_train), list(y_train)\n\n    train_encodings = tokenizer(x_train, padding=True, truncation=True)\n    train_ds = tf.data.Dataset.from_tensor_slices((\n          dict(train_encodings),\n          y_train\n      ))\n    train_ds = train_ds.batch(1)\n    \n    #test_dataset\n    x_test, y_test = list(x_train), list(y_train)\n    test_encodings = tokenizer(x_test, padding=True, truncation=True)\n    test_ds = tf.data.Dataset.from_tensor_slices(( \n          dict(test_encodings),\n          y_test\n      ))\n    test_ds = test_ds.batch(1)\n    \n    return train_ds,test_ds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgBKku71K-jN","outputId":"fa8ae0e0-4f5e-402f-847f-7508c6128b2f","execution":{"iopub.status.busy":"2023-03-22T14:27:34.668289Z","iopub.execute_input":"2023-03-22T14:27:34.668727Z","iopub.status.idle":"2023-03-22T14:27:34.678258Z","shell.execute_reply.started":"2023-03-22T14:27:34.668691Z","shell.execute_reply":"2023-03-22T14:27:34.676528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2, id2label={0: 'general', 1: 'toxic'})\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=2e-5,\n    decay_steps=10000,\n    decay_rate=0.9)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n    model.compile(optimizer=optimizer,\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  metrics=tf.metrics.SparseCategoricalAccuracy()\n                  )\n    print(model.summary())\n    return model","metadata":{"id":"C4-JM6W7MFlk","execution":{"iopub.status.busy":"2023-03-22T14:27:34.679836Z","iopub.execute_input":"2023-03-22T14:27:34.680552Z","iopub.status.idle":"2023-03-22T14:27:34.693503Z","shell.execute_reply.started":"2023-03-22T14:27:34.680512Z","shell.execute_reply":"2023-03-22T14:27:34.692428Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def fit_model(model, epochs, ds):\n    model.fit(x=ds, epochs=epochs)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbkDxzRVM9bq","outputId":"0ee74056-f713-4dc7-ed03-4a5aad4fb1ec","execution":{"iopub.status.busy":"2023-03-22T14:27:34.696101Z","iopub.execute_input":"2023-03-22T14:27:34.697100Z","iopub.status.idle":"2023-03-22T14:27:34.703574Z","shell.execute_reply.started":"2023-03-22T14:27:34.697059Z","shell.execute_reply":"2023-03-22T14:27:34.702541Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model,ds, train_test_vals):\n    from sklearn.metrics import classification_report\n    y_eval = model.predict(train_ds)\n    l = y_eval['logits']\n    preds = [] \n    for i in l:\n        prediction = tf.round(tf.nn.sigmoid(i))\n        res = np.argmax(prediction,0)\n        preds.append(res)\n    print(classifications_report(train_test_vals, preds))\n    return preds\n    ","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.706757Z","iopub.execute_input":"2023-03-22T14:27:34.707227Z","iopub.status.idle":"2023-03-22T14:27:34.714846Z","shell.execute_reply.started":"2023-03-22T14:27:34.707199Z","shell.execute_reply":"2023-03-22T14:27:34.713845Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def loss_accuracy(model, ds):\n    loss, accuracy = model.evaluate(ds)\n    print('loss = ', loss)\n    print('accuracy = ', accuracy)\n    return loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.716212Z","iopub.execute_input":"2023-03-22T14:27:34.716938Z","iopub.status.idle":"2023-03-22T14:27:34.725999Z","shell.execute_reply.started":"2023-03-22T14:27:34.716901Z","shell.execute_reply":"2023-03-22T14:27:34.725213Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#import pickle\n#filename = '1.4_model.sav'\n#pickle.dump(model, open(filename, 'wb'))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-03-22T14:27:34.730883Z","iopub.execute_input":"2023-03-22T14:27:34.731985Z","iopub.status.idle":"2023-03-22T14:27:34.736907Z","shell.execute_reply.started":"2023-03-22T14:27:34.731941Z","shell.execute_reply":"2023-03-22T14:27:34.736014Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_gradients(text, model, tokenizer):\n  def get_correct_span_mask(correct_index, token_size):\n    span_mask = np.zeros((1, token_size))\n    span_mask[0, correct_index] = 1\n    span_mask = tf.constant(span_mask, dtype='float32')\n    return span_mask\n\n  embedding_matrix = model.bert.embeddings.weights[0]\n  encoded_tokens = tokenizer(text, return_tensors=\"tf\")\n  token_ids = list(encoded_tokens[\"input_ids\"].numpy()[0])\n  vocab_size = embedding_matrix.get_shape()[0]\n\n  # convert token ids to one hot. We can't differentiate wrt to int token ids hence the need for one hot representation\n  token_ids_tensor = tf.constant([token_ids], dtype='int32')\n  token_ids_tensor_one_hot = tf.one_hot(token_ids_tensor, vocab_size)\n\n  with tf.GradientTape(watch_accessed_variables=False) as tape:\n    # (i) watch input variable\n    tape.watch(token_ids_tensor_one_hot)\n    # multiply input model embedding matrix; allows us do backprop wrt one hot input\n    inputs_embeds = tf.matmul(token_ids_tensor_one_hot,embedding_matrix)\n\n    # (ii) get prediction\n    pred_scores = model({\"inputs_embeds\": inputs_embeds, \"attention_mask\": encoded_tokens[\"attention_mask\"] } ).logits\n    print(pred_scores) \n    max_class = tf.argmax(pred_scores, axis=1).numpy()[0]\n\n    # get mask for predicted score class\n    score_mask = get_correct_span_mask(max_class, pred_scores.shape[1])\n\n    # zero out all predictions outside of the correct  prediction class; we want to get gradients wrt to just this class\n    predict_correct_class = tf.reduce_sum(pred_scores * score_mask )\n\n    # (iii) get gradient of input with respect to prediction class\n    gradient_non_normalized = tf.norm(\n        tape.gradient(predict_correct_class, token_ids_tensor_one_hot),axis=2)\n\n    # (iv) normalize gradient scores and return them as \"explanations\"\n    gradient_tensor = (\n        gradient_non_normalized /\n        tf.reduce_max(gradient_non_normalized)\n    )\n    gradients = gradient_tensor[0].numpy().tolist()\n    token_words = tokenizer.convert_ids_to_tokens(token_ids)\n\n    prediction_label= \"toxic\" if max_class == 1 else \"general\"\n  return gradients, token_words , prediction_label","metadata":{"id":"Bfiu2pQfVwSD","execution":{"iopub.status.busy":"2023-03-22T14:27:34.738425Z","iopub.execute_input":"2023-03-22T14:27:34.739151Z","iopub.status.idle":"2023-03-22T14:27:34.752856Z","shell.execute_reply.started":"2023-03-22T14:27:34.739113Z","shell.execute_reply":"2023-03-22T14:27:34.751680Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def plot_gradients(tokens,gradients, title):\n      import matplotlib.pyplot as plt\n\n      \"\"\" Plot  explanations\n      \"\"\"\n      plt.figure(figsize=(21,3))\n      xvals = [ x + str(i) for i,x in enumerate(tokens)]\n      colors =  [ (0,0,1, c) for c in (gradients) ]\n      # edgecolors = [ \"black\" if t==0 else (0,0,1, c)  for c,t in zip(gradients, token_types) ]\n      # colors =  [  (\"r\" if t==0 else \"b\")  for c,t in zip(gradients, token_types) ]\n      plt.tick_params(axis='both', which='minor', labelsize=29)\n      p = plt.bar(xvals, gradients, color=colors, linewidth=1 )\n      plt.title(title)\n      p=plt.xticks(ticks=[i for i in range(len(tokens))], labels=tokens, fontsize=12,rotation=90)","metadata":{"id":"mBIBR3d8WORT","execution":{"iopub.status.busy":"2023-03-22T14:27:34.754644Z","iopub.execute_input":"2023-03-22T14:27:34.755024Z","iopub.status.idle":"2023-03-22T14:27:34.767249Z","shell.execute_reply.started":"2023-03-22T14:27:34.754986Z","shell.execute_reply":"2023-03-22T14:27:34.766162Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def neg_pred_neg(y_test, y_pred):\n    neg_pred_neg = []\n    #probs_npn = []\n    for i in range (0,len(y_test)):\n      if y_test[i] == 1 and ans_test[i] == 1:\n        neg_pred_neg.append(x_test[i])  \n        #probs_npn.append(probs_test[i]) \n    return neg_pred_neg ","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.768934Z","iopub.execute_input":"2023-03-22T14:27:34.769497Z","iopub.status.idle":"2023-03-22T14:27:34.777543Z","shell.execute_reply.started":"2023-03-22T14:27:34.769415Z","shell.execute_reply":"2023-03-22T14:27:34.776713Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ho4x7HSWWheF","outputId":"34383322-ecc1-4387-9bfe-1c43b57f98dd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def whole_fun(s):\n    \n    embedding_matrix = model.bert.embeddings.weights[0]\n    encoded_tokens = tokenizer(s, return_tensors=\"tf\")\n    token_ids = list(encoded_tokens[\"input_ids\"].numpy()[0])\n    vocab_size = embedding_matrix.get_shape()[0]\n\n    token_ids_tensor = tf.constant([token_ids], dtype='int32')\n    token_ids_tensor_one_hot = tf.one_hot(token_ids_tensor, vocab_size)\n\n    inputs_embeds = tf.matmul(token_ids_tensor_one_hot,embedding_matrix)\n\n    # (ii) get prediction\n    pred_scores = model({\"inputs_embeds\": inputs_embeds, \"attention_mask\": encoded_tokens[\"attention_mask\"] } ).logits\n    #print(pred_scores) \n    print(expit(pred_scores))\n    max_class = tf.argmax(pred_scores, axis=1).numpy()[0]\n\n    gradients, words, label = get_gradients(s, model, tokenizer)\n    plot_gradients(words, gradients,  f\"Prediction: {label} | {s} \")\n\n    def list_of_words_to_change(words, gradients):\n        sum_ = 0\n        for i in gradients:\n            sum_ = sum_ + i\n            avg = sum_/len(gradients)\n\n        list_of_words = []\n        for i in range(0, len(gradients)):\n            if gradients[i] >= avg:\n                list_of_words.append(words[i])\n                j = i+1\n                while j<len(gradients):\n                    if words[j][0] == '#' and gradients[j]<avg:\n                        list_of_words.append(words[j])\n                        j = j+1\n                    else:\n                        i = j\n                        break\n\n        l_w = []\n        l_w.append(list_of_words[0])\n        cnt=1\n        for i in range(1,len(list_of_words)):\n            final = list_of_words[i]\n            s = list_of_words[i]\n            a = ''\n            if s[0] == '#':\n                j = 0\n                for j in range(0,len(s)):\n                    if s[j] != '#':\n                        a = a + s[j]\n                a = l_w[cnt-1] + a\n                final = a\n                if final in words:\n                    l_w[cnt-1] = final\n            else:\n                l_w.append(final)\n                cnt = cnt+1\n        return list_of_words\n    return list_of_words_to_change(words, gradients)\n    \n        \n    \n#print(whole_fun(s))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.779080Z","iopub.execute_input":"2023-03-22T14:27:34.779670Z","iopub.status.idle":"2023-03-22T14:27:34.794883Z","shell.execute_reply.started":"2023-03-22T14:27:34.779635Z","shell.execute_reply":"2023-03-22T14:27:34.793848Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = import_and_check_data()\ndf","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.796503Z","iopub.execute_input":"2023-03-22T14:27:34.796852Z","iopub.status.idle":"2023-03-22T14:27:34.879643Z","shell.execute_reply.started":"2023-03-22T14:27:34.796816Z","shell.execute_reply":"2023-03-22T14:27:34.878544Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"0    7366\n1    2694\nName: label, dtype: int64\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                   tweet  label\n0      News flash If a writer creates a SFC to answer...      0\n1                       Judgement time mkr hungrycampers      0\n2        USER USER Baphomet sent me and my family dea...      0\n3        USER Some woman was proper staring at me whi...      1\n4        USER The reality is that the caliphate is mo...      1\n...                                                  ...    ...\n10055  USER I need to be less uncomfortable talking a...      0\n10056                                am is early lol mkr      0\n10057                                           Fml LINK      0\n10058                            Then this happened LINK      0\n10059  ally in social media is a slang word my slang ...      0\n\n[10060 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>News flash If a writer creates a SFC to answer...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Judgement time mkr hungrycampers</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USER USER Baphomet sent me and my family dea...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USER Some woman was proper staring at me whi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USER The reality is that the caliphate is mo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10055</th>\n      <td>USER I need to be less uncomfortable talking a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10056</th>\n      <td>am is early lol mkr</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10057</th>\n      <td>Fml LINK</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10058</th>\n      <td>Then this happened LINK</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10059</th>\n      <td>ally in social media is a slang word my slang ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10060 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(df['tweet'], df['label'])\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.881048Z","iopub.execute_input":"2023-03-22T14:27:34.882298Z","iopub.status.idle":"2023-03-22T14:27:34.905902Z","shell.execute_reply.started":"2023-03-22T14:27:34.882256Z","shell.execute_reply":"2023-03-22T14:27:34.904498Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"len of x_train  8048\nlen of x_test  2012\n","output_type":"stream"}]},{"cell_type":"code","source":"train_ds, test_ds = train_and_test_ds(x_train,x_test,y_train,y_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:34.907447Z","iopub.execute_input":"2023-03-22T14:27:34.908243Z","iopub.status.idle":"2023-03-22T14:27:56.677378Z","shell.execute_reply.started":"2023-03-22T14:27:34.908193Z","shell.execute_reply":"2023-03-22T14:27:56.676168Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c50dedecb8f44a19aa4b0a2031e0ff8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adebc60df4644fc9111296e9b1efa38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1309f63807634653b0dff2ea29e8a9ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd0fc8946b34eb58d666406830f5f9f"}},"metadata":{}}]},{"cell_type":"code","source":"model = create_model()","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:27:56.679221Z","iopub.execute_input":"2023-03-22T14:27:56.679689Z","iopub.status.idle":"2023-03-22T14:28:04.111352Z","shell.execute_reply.started":"2023-03-22T14:27:56.679643Z","shell.execute_reply":"2023-03-22T14:28:04.106789Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/527M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6707faddc05d45328a8c99b0222b522a"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n bert (TFBertMainLayer)      multiple                  108310272 \n                                                                 \n dropout_37 (Dropout)        multiple                  0         \n                                                                 \n classifier (Dense)          multiple                  1538      \n                                                                 \n=================================================================\nTotal params: 108,311,810\nTrainable params: 108,311,810\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit model on train_ds\nfit_model(model,3,train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:28:04.113126Z","iopub.execute_input":"2023-03-22T14:28:04.114369Z","iopub.status.idle":"2023-03-22T14:49:16.243299Z","shell.execute_reply.started":"2023-03-22T14:28:04.114322Z","shell.execute_reply":"2023-03-22T14:49:16.241481Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/3\n8048/8048 [==============================] - 718s 83ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.8405\nEpoch 2/3\n6944/8048 [========================>.....] - ETA: 1:28 - loss: 0.2677 - sparse_categorical_accuracy: 0.8906","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3175151551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit model on train_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/1226826550.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, epochs, ds)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#get_preds_of_train_ds\ntrain_preds = get_predictions(model,train_ds)\n\n#loss_accuracy_on_train_ds\ntrain_loss,train_accuracy = loss_accuracy(model,train_ds)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.244969Z","iopub.status.idle":"2023-03-22T14:49:16.245843Z","shell.execute_reply.started":"2023-03-22T14:49:16.245550Z","shell.execute_reply":"2023-03-22T14:49:16.245581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = get_predictions(model,test_ds)\n\ntest_loss, test_accuracy = loss_accuracy(model,test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.247456Z","iopub.status.idle":"2023-03-22T14:49:16.248280Z","shell.execute_reply.started":"2023-03-22T14:49:16.247994Z","shell.execute_reply":"2023-03-22T14:49:16.248022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst = neg_pred_neg(y_test,test_preds)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.249835Z","iopub.status.idle":"2023-03-22T14:49:16.250706Z","shell.execute_reply.started":"2023-03-22T14:49:16.250396Z","shell.execute_reply":"2023-03-22T14:49:16.250425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('LOL USER call me sexist But i really hate girl gamer teams really really hate lol'))\nprint()\nprint(whole_fun('LOL USER call me a misogynist but,i really hate female gamer teams really really hate lol'))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"oebhd3mA5WV5","outputId":"a176149d-8b47-4141-b24c-6848c8e30e56","execution":{"iopub.status.busy":"2023-03-22T14:49:16.252246Z","iopub.status.idle":"2023-03-22T14:49:16.253056Z","shell.execute_reply.started":"2023-03-22T14:49:16.252772Z","shell.execute_reply":"2023-03-22T14:49:16.252799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('USER im not sexist but women just cant be comedians nor can they be rappers'))\nprint()\nprint(whole_fun('USER im not misogynistic but ladies really cant be entertainers nor can they be musicians'))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.254449Z","iopub.status.idle":"2023-03-22T14:49:16.255260Z","shell.execute_reply.started":"2023-03-22T14:49:16.254984Z","shell.execute_reply":"2023-03-22T14:49:16.255012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('USER I swear Im not sexist but get these women outta here when it comes to football  '))\nprint()\nprint(whole_fun('USER I swear I dont discriminate against women but get these women out of here when it comes to football  '))\nprint()\nprint(whole_fun('USER I promise Im not misogynistic nevertheless get these ladies outta here when it comes to soccer  '))\nprint()\nprint(whole_fun('USER Im not a misogynistic at all, but can we please get these girls off the football pitch?'))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.256808Z","iopub.status.idle":"2023-03-22T14:49:16.257612Z","shell.execute_reply.started":"2023-03-22T14:49:16.257323Z","shell.execute_reply":"2023-03-22T14:49:16.257350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('  USER Im not sexist but women shouldnt be allowed to drive'))\nprint()\nprint(whole_fun(\" USER Im not misogynistic but ladies oughtn't be permitted to use motorvehicles\"))\nprint()\nprint(whole_fun(\" USER I don't discriminate against the womankind but ladies shouldn't be permitted to use motorvehicles\"))\nprint()\nprint(whole_fun(\" USER I don't discriminate against the womankind but women shouldn't be permitted to use motorvehicles\"))\nprint()\nprint(whole_fun(\" USER I don't discriminate against the womankind but they shouldn't be permitted to use motorvehicles\"))\n\n\n#replaced a word with it's meaning : sexist --> discriminate against women \n#replaced woman repeating again with \"THEY\" (BASICALLY REDUCED THE NUMBER OF TIMES A TRIGGER WORD IS REPEATED)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.258983Z","iopub.status.idle":"2023-03-22T14:49:16.259722Z","shell.execute_reply.started":"2023-03-22T14:49:16.259456Z","shell.execute_reply":"2023-03-22T14:49:16.259496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('USER USER Might need some lube  The tip is wider than her hips'))\nprint()\nprint(whole_fun('USER USER Might need some lubricant  The end is more widespread than her middle'))\nprint()\nprint(whole_fun('USER USER Lubricant may be required The tip exceeds her hips in width.')) #rephrased one\nprint()\nprint(whole_fun('USER USER M1ght need some lub3  The t1p is wid3r than h3r h1ps')) #used leet speak on all words that have gradient above average\n#leetspeak used on initial sentence\nprint()\nprint(whole_fun('USER USER Might need some lube  The tip is wider than her h1ps')) #used leet speak: LEVEL 1 (changed only highest word)\nprint()\nprint(whole_fun('USER USER Might need some lube  The tip is w1d3r than h3r h1ps')) #used leet speak: LEVEL 2 (changed second highest words)\nprint()\nprint(whole_fun('USER USER M1ght need some lubr1c4nt  The end is more w1d35pr3ad than h3r middle')) #leetspeak on sentence with min prob","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.261143Z","iopub.status.idle":"2023-03-22T14:49:16.261928Z","shell.execute_reply.started":"2023-03-22T14:49:16.261657Z","shell.execute_reply":"2023-03-22T14:49:16.261684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('USER Im not sexist but I do believe that men should provide for the family and the women should stay home and take care of …'))\nprint() #replace problem words with synonyms (picked synonyms that aren't in the whole dataset, probability reduced obviously)\nprint(whole_fun('USER Im not misogynistic but I think that menfolk should finance the family and the women should stay home and take care of …',))\nprint() #paraphrase the original sentence\nprint(whole_fun('USER Im not a sexist person, but I do think its the mans responsibility to provide for his family, while the woman should stay at home and take care of...'))\nprint() #rephrase in a slightly complicated way\nprint(whole_fun('USER While I am not a sexist person, I do feel that males should be the ones who provide for their families while women should remain at home and take care of...'))\nprint() #leetspeak on the original sentence\nprint(whole_fun('USER Im not sex1s7 but I do bel13v3 7ha7 m3n sh0uld pr0v1d3 for the fam1ly and the women should st4y home and take care of …'))\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.263263Z","iopub.status.idle":"2023-03-22T14:49:16.264046Z","shell.execute_reply.started":"2023-03-22T14:49:16.263768Z","shell.execute_reply":"2023-03-22T14:49:16.263795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(whole_fun('USER Im not sexist but women working construction just isnt the same'))\nprint() #replace with synonyms\nprint(whole_fun('USER Im not misogynistic but ladies working construction just isnt the same'))\nprint() #paraphrase\nprint(whole_fun('USER Im not trying to be sexist, but its just not the same to have women working in construction.'))\nprint() #paraphrase a bit complicated\nprint(whole_fun('USER I dont mean to be offensive, but theres something missing when female workers build.'))\nprint() #leetspeak on high gradient words\nprint(whole_fun(''))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T14:49:16.265425Z","iopub.status.idle":"2023-03-22T14:49:16.266292Z","shell.execute_reply.started":"2023-03-22T14:49:16.266002Z","shell.execute_reply":"2023-03-22T14:49:16.266031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}